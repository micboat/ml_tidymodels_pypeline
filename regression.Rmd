# Description

encoding: utf-8
press "ctrl + shift + o (windows)" to show document outline
press "alt + o" to collapse all
press "alt + shift + o" to expand all

# Load Librarys

```{r}
library(tidyverse)
library(tidymodels)
library(naniar)     # vis_miss
library(janitor)    # rename colnames to under score
library(furrr)      # parallel
library(rlang)      # expression
library(earth)      # modeling mars
library(xgboost)    # modeling xgboost
library(lightgbm)   # modeling lgbm
library(Matrix)     # modeling lgbm
library(tictoc)     # time check
library(patchwork)  # plot
source("func.R")
```

# Read Data 

**depends on project**

```{r}
data <- diamonds
glimpse(diamonds)
```

# EDA

**depends on project**
**or separate the scripts**

```{r}
# vis_miss(data)
```



# Split the Data and CV Data

```{r}
set.seed(7777)
splits <- data %>% initial_split(prop = 0.8)

train <- training(splits)
test <- testing(splits)

data_cv <- train %>% vfold_cv(v = 5) 
  
```

# Recipes (Preprocessing)

```{r}
# set target_var
target_var <- sym("carat")
# set estimate type
mode_reg_or_clas <- "regression"
# set formura
formula <- expr(formula(!!target_var ~ .))
# set recipes
rec <-
  data %>%
  recipe(formula = formula) %>%
  step_ordinalscore(cut, color, clarity)

rec_preped <-
  rec %>%
  prep()
```


# No Parameter Tuning

## Prepare the Model

```{r}
# # Logistic regression 
# logit_tune <- 
#   logistic_reg(penalty = tune(), 
#                mixture = tune()) %>%
#   set_engine("glmnet")
# 
# # Hyperparameter grid
# logit_grid <- logit_tune_pra %>%
#   parameters() %>%
#   grid_max_entropy(size = 5)
# 
# # Workflow bundling every step 
# logit_wflow <- workflow() %>%
#   add_recipe(rec) %>%
#   add_model(logit_tune_pra)

# random forest
model_rf <-
  rand_forest() %>%
  set_engine("ranger") %>%
  set_mode(mode_reg_or_clas)

wflow_rf <-
  workflow() %>%
  add_recipe(rec) %>%
  add_model(model_rf)

# mars model
model_mars <-
  mars() %>%
  set_engine("earth") %>%
  set_mode(mode_reg_or_clas)

wflow_mars <-
  workflow() %>%
  add_recipe(rec) %>%
  add_model(model_mars)

#boosted trees
model_xgb <-
  boost_tree() %>%
  set_engine("xgboost") %>%
  set_mode(mode_reg_or_clas)

wflow_xgb <-
  workflow() %>%
  add_recipe(rec) %>%
  add_model(model_xgb)

#neural nets
model_keras <-
  mlp() %>%
  set_engine("keras") %>%
  set_mode(mode_reg_or_clas)

wflow_keras <-
  workflow() %>%
  add_recipe(rec) %>%
  add_model(model_keras)
```

## Soro model

### xgboost

```{r}
# fitting
fit_xgb <- fit(wflow_xgb, train)

# predict test, and pred to the column
res_xgb <-
  test %>%
  bake(rec_preped, new_data = .) %>%
  tidypredict::tidypredict_to_column(df = ., fit_xgb$fit$fit$fit)
```

#### feature importance (xgb)

```{r}
my_importance_plot(fit_xgb, res_xgb)
```

### lightGBM

```{r}
lgb_dataset <-
  create_lgb_dataset(target_var = target_var,
                     rec_preped = rec_preped,
                     test = test)
params <-
  list(objective = "regression",
       metric = "rmse")

```

```{r}
tic()
fit_lgb <-
  lgb.train(params = params,
            data = lgb_dataset$lgb_data)
toc()
```
     
#### feature importance (lgb)

```{r}
res_lgb <-
  test %>%
  bind_cols(fit = predict(fit_lgb, lgb_dataset$lgb_test_mat))

my_importance_plot(fit_lgb, res_lgb)
```

### metric (xgb and lgb)

```{r}
bind_rows(
  res_xgb %>% metrics(carat, fit) %>% mutate(boost = "xgb"),
  res_lgb %>% metrics(carat, fit) %>% mutate(boost = "lgb")
) %>%
  arrange(.metric) %>% 
  select(-.estimator)
```

**maybe return to EDA and preprocessing**

## Cross Validation

### Create Wflow List

```{r}
wflow_list_no_tuning <-
  list(rf = wflow_rf, mars = wflow_mars)
```

### Modeling by No Tuning CV

```{r}
plan(multiprocess)
fits_no_tuning <- fit_cv_no_tuning(wflow_list_no_tuning)
```

# Tuning 

## Prepare the Models (tuning)

```{r}
# # Logistic regression 
# tune_logit <- 
#   logistic_reg(penalty = tune(), 
#                mixture = tune()) %>%
#   set_engine("glmnet")
# 
# # Hyperparameter grid
# grid_logit <-
#   tune_logit %>%
#   parameters() %>%
#   grid_max_entropy(size = 5)
# 
# # Workflow bundling every step 
# wflow_logit <- 
#   workflow() %>%
#   add_recipe(rec) %>%
#   add_model(tune_logit)

# random forest
tune_rf <- 
  rand_forest(mtry = tune(), 
              trees = tune()) %>%
  set_engine("ranger") %>%
  set_mode(mode_reg_or_clas)

grid_rf <- 
  tune_rf %>%
  parameters() %>%
  finalize(select(data, -target_var)) %>%  
  grid_max_entropy(size = 5)

wflow_rf <-
  workflow() %>%
  add_recipe(rec) %>%
  add_model(tune_rf)

# mars model
tune_mars <-
  mars(num_terms = tune(), 
       prod_degree = 2,
       prune_method = tune()) %>%
  set_engine("earth") %>%
  set_mode(mode_reg_or_clas)

grid_mars <- 
  tune_mars %>%
  parameters() %>%
  grid_max_entropy(size = 5)

wflow_mars <-
  workflow() %>%
  add_recipe(rec) %>%
  add_model(tune_mars)

#boosted trees
tune_xgb <- 
  boost_tree(mtry = tune(), 
             tree = tune(),
             learn_rate = tune(),
             tree_depth = tune()) %>%
  set_engine("xgboost") %>%
  set_mode(mode_reg_or_clas)

grid_xgb <- tune_xgb %>%
  parameters() %>%
  finalize(select(data, -target_var)) %>%
  grid_max_entropy(size = 5)

wflow_xgb <- 
  workflow() %>%
  add_recipe(rec) %>%
  add_model(tune_xgb)

#neural nets
tune_keras <- 
  mlp(hidden_units = tune(), 
      penalty = tune(),
      activation = "relu") %>%
  set_engine("keras") %>%
  set_mode(mode_reg_or_clas)

grid_keras <- 
  tune_keras %>%
  parameters() %>%
  grid_max_entropy(size = 5)

wflow_keras <- 
  workflow() %>%
  add_recipe(rec) %>%
  add_model(tune_keras)
```


## Create Wflow and Grid List  (tuning)

```{r}
wflow_list_tuning <-
  list(rf = wflow_rf, xgb = wflow_xgb)
grid_list <-
  list(rf = grid_rf, xgb = grid_xgb)
```

## Modeling by Tuning CV

```{r}
plan(multiprocess)
fits_tuning <- fit_cv_tuning(wflow_list_tuning, grid_list)
```

```{r}
rm(fits)
fits_no_tuning$fit %>% map(collect_metrics)
fits_no_tuning$fit %>% map(collect_predictions)

fits_tuning$fit %>% map(collect_metrics)
fits_tuning$fit %>% map(collect_predictions)

fits_tuning$fit %>% map(show_best, metric = "rmse")
```



